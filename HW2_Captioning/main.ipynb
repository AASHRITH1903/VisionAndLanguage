{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from dataset import MiniFlickrDataset, get_loader\n",
    "from todo import CaptioningModel\n",
    "from trainer import Trainer\n",
    "from lr_warmup import LRWarmup\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_path = 'dataset.pkl'\n",
    "        self.clip_model = 'openai/clip-vit-base-patch32'\n",
    "        self.text_model = 'gpt2'\n",
    "        self.seed = 100\n",
    "        self.num_workers = 0\n",
    "        self.train_size = 0.84\n",
    "        self.val_size = 0.13\n",
    "        self.test_size = 100\n",
    "        self.epochs = 1 #10\n",
    "        self.lr = 3e-3\n",
    "        self.k = 0.33\n",
    "        self.batch_size_exp = 6\n",
    "        self.ep_len = 4\n",
    "        self.num_layers = 6\n",
    "        self.n_heads = 16\n",
    "        self.forward_expansion = 4\n",
    "        self.max_len = 40\n",
    "        self.dropout = 0.1\n",
    "config = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\transformers\\modeling_utils.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlr)\n\u001b[0;32m     39\u001b[0m warmup \u001b[38;5;241m=\u001b[39m LRWarmup(epochs\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mepochs, max_lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlr, k\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mk)\n\u001b[1;32m---> 40\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLambdaLR\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_warmup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Create trainer\u001b[39;00m\n\u001b[0;32m     43\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     44\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     45\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:327\u001b[0m, in \u001b[0;36mLambdaLR.__init__\u001b[1;34m(self, optimizer, lr_lambda, last_epoch, verbose)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39mparam_groups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lr_lambdas, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lr_lambda)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m         )\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_lambdas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(lr_lambda)\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:139\u001b[0m, in \u001b[0;36mLRScheduler.__init__\u001b[1;34m(self, optimizer, last_epoch, verbose)\u001b[0m\n\u001b[0;32m    137\u001b[0m patch_track_step_called(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m _check_verbose_deprecated_warning(verbose)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:144\u001b[0m, in \u001b[0;36mLRScheduler._initial_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize step counts and performs a step\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:230\u001b[0m, in \u001b[0;36mLRScheduler.step\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 230\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(EPOCH_DEPRECATION_WARNING, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:376\u001b[0m, in \u001b[0;36mLambdaLR.get_lr\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    374\u001b[0m     _warn_get_lr_called_within_step(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    377\u001b[0m         base_lr \u001b[38;5;241m*\u001b[39m lmbda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch)\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m lmbda, base_lr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_lambdas, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_lrs)\n\u001b[0;32m    379\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\MTSS\\VirtualEnvs\\dev-env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:377\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    374\u001b[0m     _warn_get_lr_called_within_step(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 377\u001b[0m         base_lr \u001b[38;5;241m*\u001b[39m \u001b[43mlmbda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m lmbda, base_lr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_lambdas, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_lrs)\n\u001b[0;32m    379\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\MTSS\\Downloads\\Fall24_CSE597_Homework2\\Fall24_CSE597_Homework2\\VisionAndLanguage\\HW2_Captioning\\lr_warmup.py:19\u001b[0m, in \u001b[0;36mLRWarmup.lr_warmup\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlr_warmup\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch):\n\u001b[1;32m---> 19\u001b[0m     a_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_lr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_point\u001b[49m\n\u001b[0;32m     20\u001b[0m     a_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_lr \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_point \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[0;32m     22\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m a_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "device = utils.init_env(config.seed)\n",
    "\n",
    "# Create data loaders\n",
    "dataset = MiniFlickrDataset(config.data_path)\n",
    "config.train_size = int(config.train_size * len(dataset))\n",
    "config.val_size = len(dataset) - config.train_size - config.test_size\n",
    "train_dataset, val_dataoet, test_dataset = random_split(dataset, [config.train_size, config.val_size, config.test_size])\n",
    "train_loader = get_loader(\n",
    "    train_dataset, \n",
    "    bs_exp=config.batch_size_exp, \n",
    "    shuffle=True, \n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = get_loader(\n",
    "    test_dataset,\n",
    "    bs_exp=0,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "# Creat model\n",
    "model = CaptioningModel(\n",
    "    clip_model=config.clip_model,\n",
    "    text_model=config.text_model,\n",
    "    ep_len=config.ep_len,\n",
    "    num_layers=config.num_layers, \n",
    "    n_heads=config.n_heads, \n",
    "    forward_expansion=config.forward_expansion, \n",
    "    dropout=config.dropout, \n",
    "    max_len=config.max_len,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Create optimizer, lr scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "warmup = LRWarmup(epochs=config.epochs, max_lr=config.lr, k=config.k)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, warmup.lr_warmup)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scaler=torch.cuda.amp.GradScaler(),\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# use _load_ckpt method of the trainer to load weights from the saved checkpoint to resume the training. Below is a sample code for the same\n",
    "\n",
    "#trainer._load_ckp(\"path to .pt file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for img_emb, input_ids, attention_mask in train_loader:\n",
    "\n",
    "#     print(img_emb.shape)\n",
    "#     print(input_ids.shape)\n",
    "#     print(attention_mask.shape)\n",
    "\n",
    "#     loss = model.train_forward(\n",
    "#         img_emb= img_emb.to(device),\n",
    "#         trg_cap= input_ids.to(device),\n",
    "#         att_mask= attention_mask.to(device)\n",
    "#     )\n",
    "\n",
    "#     print('\\n', loss)\n",
    "\n",
    "#     if i > 1:\n",
    "#         break\n",
    "\n",
    "#     i += 1\n",
    "#     print()\n",
    "\n",
    "\n",
    "# # model.train_forward(\n",
    "# #     img_emb=\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "for epoch in range(trainer.epoch, config.epochs):\n",
    "    trainer.train_epoch()\n",
    "\n",
    "    score = trainer.test_epoch()\n",
    "    print(\"Score: {:.4f}\".format(score))\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    if (epoch + 1) % 3 == 0:\n",
    "        trainer.save_ckp(os.path.join(\"checkpoints\", f'epoch_{epoch + 1}.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
